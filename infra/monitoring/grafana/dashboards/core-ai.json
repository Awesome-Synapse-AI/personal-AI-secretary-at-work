{
  "id": null,
  "title": "Core AI Observability",
  "timezone": "browser",
  "schemaVersion": 38,
  "version": 1,
  "refresh": "10s",
  "panels": [
    {
      "type": "timeseries",
      "title": "HTTP Request Rate",
      "datasource": {"type": "prometheus", "uid": "Prometheus"},
      "targets": [
        {
          "expr": "sum by (path,method,status) (rate(core_ai_http_requests_total[5m]))",
          "legendFormat": "{{method}} {{path}} ({{status}})"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
    },
    {
      "type": "timeseries",
      "title": "HTTP Latency p95",
      "datasource": {"type": "prometheus", "uid": "Prometheus"},
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum by (le,path,method) (rate(core_ai_http_request_duration_seconds_bucket[5m])))",
          "legendFormat": "{{method}} {{path}}"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
    },
    {
      "type": "timeseries",
      "title": "LLM Latency p95",
      "datasource": {"type": "prometheus", "uid": "Prometheus"},
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum by (le,model,streaming) (rate(core_ai_llm_request_duration_seconds_bucket[5m])))",
          "legendFormat": "{{model}} (stream={{streaming}})"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
    },
    {
      "type": "stat",
      "title": "LLM Error Rate (5m)",
      "datasource": {"type": "prometheus", "uid": "Prometheus"},
      "targets": [
        {
          "expr": "sum(rate(core_ai_llm_request_errors_total[5m]))"
        }
      ],
      "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
    }
  ]
}
